{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c634c8",
   "metadata": {},
   "source": [
    "# üîê Invisible Watermark Training Notebook\n",
    "### PhotoMaker CAP C6 Group 3 ‚Äî Paresh\n",
    "\n",
    "This notebook trains the CNN-based invisible watermark encoder/decoder.\n",
    "- Loads CIFAR10\n",
    "- Applies robustness attacks\n",
    "- Trains encoder + decoder jointly\n",
    "- Saves `encoder_trained.pth` and `decoder_trained.pth`\n",
    "- Includes verification test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387a4f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BIT_LENGTH = 64\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19c351",
   "metadata": {},
   "source": [
    "## üìå Encoder & Decoder (same as your project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dbf7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WatermarkEncoder(nn.Module):\n",
    "    def __init__(self, bit_length=64):\n",
    "        super().__init__()\n",
    "        self.bit_length = bit_length\n",
    "\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Linear(bit_length, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64 * 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, bits):\n",
    "        B, C, H, W = image.shape\n",
    "        wm = self.embed(bits).view(B, 1, 64, 64)\n",
    "        wm = torch.nn.functional.interpolate(wm, size=(H, W), mode=\"bilinear\")\n",
    "        x = torch.cat([image, wm], dim=1)\n",
    "        residual = self.conv(x)\n",
    "        return torch.clamp(image + 0.01 * residual, 0, 1)\n",
    "\n",
    "\n",
    "class WatermarkDecoder(nn.Module):\n",
    "    def __init__(self, bit_length=64):\n",
    "        super().__init__()\n",
    "        self.bit_length = bit_length\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, bit_length),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.conv(image)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c61c22a",
   "metadata": {},
   "source": [
    "## üìå Robustness Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccadb959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "to_pil = T.ToPILImage()\n",
    "to_tensor = T.ToTensor()\n",
    "\n",
    "def jpeg_compress_single(img, quality=70):\n",
    "    \"\"\"JPEG compress a single image tensor: C√óH√óW.\"\"\"\n",
    "    pil = to_pil(img.cpu())\n",
    "    buffer = io.BytesIO()\n",
    "    pil.save(buffer, format=\"JPEG\", quality=quality)\n",
    "    buffer.seek(0)\n",
    "    return to_tensor(Image.open(buffer)).to(img.device)\n",
    "\n",
    "def apply_attacks(batch):\n",
    "    \"\"\"Apply robustness attacks to a batch of images: B√óC√óH√óW.\"\"\"\n",
    "    attacked = []\n",
    "\n",
    "    for img in batch:  # iterate over each image in the batch\n",
    "        x = img.clone()\n",
    "\n",
    "        # Gaussian noise\n",
    "        x = x + 0.01 * torch.randn_like(x)\n",
    "\n",
    "        # Random blur\n",
    "        if torch.rand(1).item() < 0.3:\n",
    "            x = torchvision.transforms.functional.gaussian_blur(x, kernel_size=5)\n",
    "\n",
    "        # JPEG compression\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            x = jpeg_compress_single(x, quality=70)\n",
    "\n",
    "        attacked.append(torch.clamp(x, 0, 1))\n",
    "\n",
    "    return torch.stack(attacked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed134413",
   "metadata": {},
   "source": [
    "## üìå Load CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b6e11bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9545ca",
   "metadata": {},
   "source": [
    "## üöÄ Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23174e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 ‚Äî img_loss=0.0000, wm_loss=0.6932\n",
      "Epoch 2/30 ‚Äî img_loss=0.0000, wm_loss=0.6934\n",
      "Epoch 3/30 ‚Äî img_loss=0.0000, wm_loss=0.6931\n",
      "Epoch 4/30 ‚Äî img_loss=0.0000, wm_loss=0.6934\n"
     ]
    }
   ],
   "source": [
    "encoder = WatermarkEncoder(BIT_LENGTH).to(DEVICE)\n",
    "decoder = WatermarkDecoder(BIT_LENGTH).to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-4)\n",
    "\n",
    "lambda_img = 1.0\n",
    "lambda_wm = 5.0\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for imgs, _ in loader:\n",
    "        imgs = imgs.to(DEVICE)\n",
    "\n",
    "        bits = torch.randint(0, 2, (imgs.size(0), BIT_LENGTH), device=DEVICE).float()\n",
    "\n",
    "        watermarked = encoder(imgs, bits)\n",
    "        attacked = apply_attacks(watermarked)\n",
    "        pred_bits = decoder(attacked)\n",
    "\n",
    "        img_loss = F.mse_loss(watermarked, imgs)\n",
    "        wm_loss = F.binary_cross_entropy(pred_bits, bits)\n",
    "\n",
    "        loss = lambda_img * img_loss + lambda_wm * wm_loss\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} ‚Äî img_loss={img_loss.item():.4f}, wm_loss={wm_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140e23fe",
   "metadata": {},
   "source": [
    "## üíæ Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd5d6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved encoder_trained.pth and decoder_trained.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(encoder.state_dict(), \"encoder_trained.pth\")\n",
    "torch.save(decoder.state_dict(), \"decoder_trained.pth\")\n",
    "print(\"Saved encoder_trained.pth and decoder_trained.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec085c8",
   "metadata": {},
   "source": [
    "## üîç Verification Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6493910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded bits: [0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1]\n",
      "Confidence: 0.65625\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "sample_img, _ = dataset[0]\n",
    "sample_img = sample_img.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "test_bits = torch.randint(0, 2, (1, BIT_LENGTH), device=DEVICE).float()\n",
    "\n",
    "wm_img = encoder(sample_img, test_bits)\n",
    "decoded = decoder(wm_img)\n",
    "\n",
    "decoded_bits = (decoded > 0.5).int().cpu().numpy().tolist()[0]\n",
    "confidence = sum(decoded_bits) / BIT_LENGTH\n",
    "\n",
    "print(\"Decoded bits:\", decoded_bits)\n",
    "print(\"Confidence:\", confidence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
